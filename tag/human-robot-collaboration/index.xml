<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Human-Robot Collaboration | Industrial AI Group @ UOA</title>
    <link>https://uoa-iai.github.io/tag/human-robot-collaboration/</link>
      <atom:link href="https://uoa-iai.github.io/tag/human-robot-collaboration/index.xml" rel="self" type="application/rss+xml" />
    <description>Human-Robot Collaboration</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 18 Dec 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://uoa-iai.github.io/media/icon_hubb891712c49b4784dd7e680d44157331_31819_512x512_fill_lanczos_center_3.png</url>
      <title>Human-Robot Collaboration</title>
      <link>https://uoa-iai.github.io/tag/human-robot-collaboration/</link>
    </image>
    
    <item>
      <title>Best Paper Award at the 51st International Conference on Computers and Industrial Engineering (CIE51), 2024</title>
      <link>https://uoa-iai.github.io/post/cie-best-paper/</link>
      <pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://uoa-iai.github.io/post/cie-best-paper/</guid>
      <description>&lt;p&gt;We are delighted to share that Ilango Kandasamy and Yuqian Lu just won a Best Paper Award at the recently concluded 51st International Conference on Computers and Industrial Engineering (CIE51), 9-11 December 2024, at UNSW Sydney, Australia, for his paper &amp;lsquo;Instructing Collaborative Robots using Large Language Models for Human-Robot Collaboration&amp;rsquo;. Ilango Kandasamy has recently completed his Master of Robotics &amp;amp; Automation Engineering programme.&lt;/p&gt;
&lt;p&gt;Below is the abstract of the paper:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;The future of smart manufacturing hinges on robots enhancing performance and productivity, but the complex communication interface between humans and robots remains a challenge. Using natural language instructions to guide robots during collaboration will significantly improve human-robot interaction. Despite the efforts to improve the robot’s ability to interpret natural language instructions, progress has been limited due to the weak generalisation and adaptability of traditional robot programming methods. Pre-trained Large Language Models (LLMs) trained on huge volumes of text data excel in Natural Language processing tasks such as semantic parsing and automatic text generation. In this study, we explored using LLMs to comprehend the basic industrial assembly instructions in natural language and convert them into low-level tasks for robots to execute additional training. We used the assembly instructions from the HA-ViD dataset to evaluate the performance of GPT-3.5 model in semantic parsing of these instructions. The GPT-3.5 demonstrated excellent generalisation in converting previously unseen industrial assembly instructions by learning from prompts. Additionally, we explored the possibility of using Vision Language Models (VLM) for object detection tasks in a novel scenario by prompting them with text input to specify target objects to be detected in the image. Finally, we proposed an end-to-end system architecture to illustrate the integration of voice and LLMs, demonstrating the performance of GPT-3.5 in converting natural language instruction into low-level robot actions for industrial assembly tasks.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>We are hiring - full PhD scholarships and post-doc position on human-robot collaboration (MBIE Endeavour Fund)</title>
      <link>https://uoa-iai.github.io/post/mbie_position/</link>
      <pubDate>Thu, 19 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://uoa-iai.github.io/post/mbie_position/</guid>
      <description>&lt;p&gt;We are excited that the IAI Research Group has been awarded $1 million over 3 years from Ministry of Business, Innovation and Employment (MBIE) Endeavour Fund to work on “Ultra-flexible human-robot collaborative product assembly”.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The manufacturing industry in Aotearoa New Zealand faces a longstanding productivity challenge due to the unsuitability of traditional automation methods for its high-mix-low-volume nature. To address this, we will develop ultra-flexible smooth human-robot collaboration technologies. These innovations will enable seamless interaction between humans and robots in dynamic manufacturing setups, particularly in product assembly, through advanced cognitive capabilities. Robots equipped with real-time human state sensing, reasoning, and adaptive behaviour planning will understand and respond to human physical and cognitive states, enhancing productivity. Multimodal human-robot communication interfaces will ensure accessibility and cultural relevance, including support for te reo Māori.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;The team comprises experts in human sensing, robot control, human-machine interactions, and Māori knowledge, ensuring a comprehensive approach. We will collaborate closely with stakeholders throughout the project, including government agencies, industry associations, end-users, consultants, and Māori and Pacific communities. By co-designing the technology with key industry partners, we will ensure its effectiveness and commercial viability. Ultimately, the project seeks to revolutionise manufacturing automation in New Zealand and globally, leading to improved productivity, product quality, and economic benefits. The advanced robot control technologies will also have global applications and can be exported as high-value software packages. Importantly, the project incorporates Tikanga following Māori data sovereignty principles and aims to support workplace well-being for Māori and all New Zealanders, emphasising cultural sensitivity and inclusivity in technology development.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Two PhD Scholarships and One Postdoc Research Fellow Position Available&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We are looking for two full scholarship PhD students and one post-doc researcher to join us. Please check the job descriptions for information on project details, candidate requirements and application processes: &lt;a href=&#34;https://uoa-iai.github.io/uploads/2024mbiejobs.pdf&#34; target=&#34;_blank&#34;&gt;Job Details&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Application Deadline: &lt;strong&gt;1st November 2024&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For further information, feel free to contact: Dr. Yuqian Lu (&lt;a href=&#34;mailto:yuqian.lu@auckland.ac.nz&#34;&gt;yuqian.lu@auckland.ac.nz&lt;/a&gt;).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Human-centric human-robot collaboration</title>
      <link>https://uoa-iai.github.io/project/human_centric_manufacturing/</link>
      <pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://uoa-iai.github.io/project/human_centric_manufacturing/</guid>
      <description>&lt;p&gt;With recent advancements in industrial robotics, the rise of reconfigurable collaborative work cells where humans and robots can work in close proximity has become more apparent. This setting enables the utilization of both humans&amp;rsquo; and robots&amp;rsquo; skills and assets to create flexible manufacturing systems capable of producing high variability products. However, poor integration between humans and robots can lead to lower productivity and higher worker stress unless human wellness is constantly monitored and optimized. This research aims to advance the current theories of Human-Robot Collaboration (HRC) to maximize manufacturing productivity and human wellness by defining, monitoring, and optimizing human fatigue levels during dynamic human-robot task allocation. New methods will be developed to optimize human wellness and manage contingencies by allocating resources based on real-time task progress and human fatigue levels. This research&amp;rsquo;s success will lead to a greater understanding of collaborative work cells in unstructured manufacturing settings.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Publications&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span class=&#34;author-highlighted&#34;&gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/yuqian-lu/&#34;&gt;Yuqian Lu&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/j.s.-adrados/&#34;&gt;J.S. Adrados&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/s.saahil-chand/&#34;&gt;S.Saahil Chand&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/l.-wang/&#34;&gt;L. Wang&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://uoa-iai.github.io/publication/lu-2021734/&#34;&gt;Humans Are Not Machines—Anthropocentric Human–Machine Symbiosis for Ultra-Flexible Smart Manufacturing&lt;/a&gt;.
  &lt;em&gt;Engineering&lt;/em&gt;.
  
  &lt;p&gt;








  





&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/lu-2021734/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.eng.2020.09.018&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108544518&amp;amp;doi=10.1016%2fj.eng.2020.09.018&amp;amp;partnerID=40&amp;amp;md5=631158d3ed1fd159d1153a804505ef85&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;













  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span class=&#34;author-highlighted&#34;&gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/yuqian-lu/&#34;&gt;Yuqian Lu&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/h.-zheng/&#34;&gt;H. Zheng&lt;/a&gt;&lt;/span&gt;, &lt;span class=&#34;author-highlighted&#34;&gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/saahil-chand/&#34;&gt;Saahil Chand&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/w.-xia/&#34;&gt;W. Xia&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/z.-liu/&#34;&gt;Z. Liu&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/x.-xu/&#34;&gt;X. Xu&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/l.-wang/&#34;&gt;L. Wang&lt;/a&gt;&lt;/span&gt;, &lt;span class=&#34;author-highlighted&#34;&gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/zhaojun-qin/&#34;&gt;Zhaojun Qin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/j.-bao/&#34;&gt;J. Bao&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://uoa-iai.github.io/publication/lu-2022612/&#34;&gt;Outlook on human-centric manufacturing towards Industry 5.0&lt;/a&gt;.
  &lt;em&gt;Journal of Manufacturing Systems&lt;/em&gt;.
  
  &lt;p&gt;








  





&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/lu-2022612/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jmsy.2022.02.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124194311&amp;amp;doi=10.1016%2fj.jmsy.2022.02.001&amp;amp;partnerID=40&amp;amp;md5=6a7af53d59e62cce4e6adf5a984de1e8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;













  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span class=&#34;author-highlighted&#34;&gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/saahil-chand/&#34;&gt;Saahil Chand&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/a.j.-mcdaid/&#34;&gt;A.J. McDaid&lt;/a&gt;&lt;/span&gt;, &lt;span class=&#34;author-highlighted&#34;&gt;
      &lt;a href=&#34;https://uoa-iai.github.io/authors/yuqian-lu/&#34;&gt;Yuqian Lu&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://uoa-iai.github.io/publication/chand-20211940/&#34;&gt;Isometric-Based Approach for Detecting Localized Muscular Fatigue during Complex Dynamic Manufacturing Operations&lt;/a&gt;.
  &lt;em&gt;IEEE International Conference on Automation Science and Engineering&lt;/em&gt;.
  
  &lt;p&gt;








  





&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/chand-20211940/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/CASE49439.2021.9551478&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117029351&amp;amp;doi=10.1109%2fCASE49439.2021.9551478&amp;amp;partnerID=40&amp;amp;md5=0e8c20ada431c12ba7b1e8611381acc9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>HA-ViD: Human Assembly Video Dataset</title>
      <link>https://uoa-iai.github.io/initiative/havid/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://uoa-iai.github.io/initiative/havid/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HR-SAT: Human-Robot Shared Asssembly Taxonomy</title>
      <link>https://uoa-iai.github.io/initiative/hrsat/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://uoa-iai.github.io/initiative/hrsat/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
