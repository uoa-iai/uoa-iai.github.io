@conference{Tao2022,
 abbrev_source_title = {Proc. IEEE Asia-Pacific Conf. Comput. Sci. Data Eng., CSDE},
 abstract = {Abstract-Running deep neural networks on low-power micro-controllers has become increasingly practical with the advance-ment in algorithm and hardware design. However, hardware resource limitations such as battery capacity still remains as a bottleneck which prevents the deployment of large classifi-cation algorithms. Model compression techniques address this issue through algorithmic means. This work investigates model compression methods, pruning and quantization, to optimize a ResNet-18 model for bird call classification. The investigation identifies the contribution of the quantization resolution and pruning sparsity towards the energy consumption, power con-sumption, inference time, performance accuracy, computational complexity, and the memory size. Â© 2022 IEEE.},
 affiliation = {University of Auckland, Acoustics Research Centre, Department of Mechanical and Mechatronics Engineering, Auckland, New Zealand},
 author = {Tao, Y. and Hioka, Y. and Lu, Y.},
 document_type = {Conference Paper},
 doi = {10.1109/CSDE56538.2022.10089354},
 isbn = {9781665453059},
 journal = {Proceedings of IEEE Asia-Pacific Conference on Computer Science and Data Engineering, CSDE 2022},
 language = {English},
 note = {cited By 0},
 publisher = {Institute of Electrical and Electronics Engineers Inc.},
 source = {Scopus},
 title = {Experimental energy consumption analysis of neural network model compression methods on microcontrollers with applications in bird call classification},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153686013&doi=10.1109%2fCSDE56538.2022.10089354&partnerID=40&md5=41bb9731201d10c998e5c5f3dba46dc4},
 year = {2022}
}
